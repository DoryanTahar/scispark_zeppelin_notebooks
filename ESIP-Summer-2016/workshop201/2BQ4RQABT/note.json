{
  "paragraphs": [
    {
      "text": "%md\n##SciSpark: Lazy evaluation, pipelines and efficiency\nThe purpose of this notebook is to further explore the concept of lazy evaluation in SciSpark inorder to maximize the scientific Resilient Distributed Dataset (sRDD).\n",
      "dateUpdated": "Jul 14, 2016 3:12:16 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465415405253_-77993761",
      "id": "20160608-125005_1817777981",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eSciSpark: Lazy evaluation, pipelines and efficiency\u003c/h2\u003e\n\u003cp\u003eThe purpose of this notebook is to further explore the concept of lazy evaluation in SciSpark inorder to maximize the scientific Resilient Distributed Dataset (sRDD).\u003c/p\u003e\n"
      },
      "dateCreated": "Jun 8, 2016 12:50:05 PM",
      "dateStarted": "Jul 14, 2016 3:12:15 AM",
      "dateFinished": "Jul 14, 2016 3:12:19 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n###What is lazy evaluation?\nLazy evaluation, also known as *delayed evaluation* or *call-by-need* is a common evaluation technique in functional programming languages. In this evaluation, a variable is not evaluated when it is assigned to a variable, but rather when the variable (evaluator) is forced to produce the expression\u0027s result.  \nFor example, let\u0027s define a function for finding the square. \n\n```\ndef square (x:Int): Int \u003d{\n    x*x\n}\n\nval y \u003d { println(square(1)); println (square(3+3+3)); \"here\" + \u0027 \u0027 + square(1).toString+ \u0027 \u0027+ square(3+3+3).toString }\nprintln(\"now\")\nprintln(y)\n```\nOutput:\n```\n1 \n81 \nnow \nhere! 1 81\n```\nIn this example, the function **square** is defined. The variable y is a function that prints the evaluation **square** of 1, prints the evaluatuation of **square** of a computation, and the string \"Here\" appeneded to the evaluations of **square**. Note the expressiveness of the 2nd function call. The ``println`` in the variable assignment of *y* triggers the execution of the **square** function. As such, the control flow for execution is: the first print statement evaluates, followed by the second print statement (for the function), then the *now* prints followed by *y*.\n",
      "dateUpdated": "Jul 7, 2016 1:30:10 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465422284424_477620803",
      "id": "20160608-144444_1134806013",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eWhat is lazy evaluation?\u003c/h3\u003e\n\u003cp\u003eLazy evaluation, also known as \u003cem\u003edelayed evaluation\u003c/em\u003e or \u003cem\u003ecall-by-need\u003c/em\u003e is a common evaluation technique in functional programming languages. In this evaluation, a variable is not evaluated when it is assigned to a variable, but rather when the variable (evaluator) is forced to produce the expression\u0027s result.\n\u003cbr  /\u003eFor example, let\u0027s define a function for finding the square.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef square (x:Int): Int \u003d{\n    x*x\n}\n\nval y \u003d { println(square(1)); println (square(3+3+3)); \"here\" + \u0027 \u0027 + square(1).toString+ \u0027 \u0027+ square(3+3+3).toString }\nprintln(\"now\")\nprintln(y)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOutput:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e1 \n81 \nnow \nhere! 1 81\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this example, the function \u003cstrong\u003esquare\u003c/strong\u003e is defined. The variable y is a function that prints the evaluation \u003cstrong\u003esquare\u003c/strong\u003e of 1, prints the evaluatuation of \u003cstrong\u003esquare\u003c/strong\u003e of a computation, and the string \u0026ldquo;Here\u0026rdquo; appeneded to the evaluations of \u003cstrong\u003esquare\u003c/strong\u003e. Note the expressiveness of the 2nd function call. The \u003ccode\u003eprintln\u003c/code\u003e in the variable assignment of \u003cem\u003ey\u003c/em\u003e triggers the execution of the \u003cstrong\u003esquare\u003c/strong\u003e function. As such, the control flow for execution is: the first print statement evaluates, followed by the second print statement (for the function), then the \u003cem\u003enow\u003c/em\u003e prints followed by \u003cem\u003ey\u003c/em\u003e.\u003c/p\u003e\n"
      },
      "dateCreated": "Jun 8, 2016 2:44:44 PM",
      "dateStarted": "Jul 7, 2016 1:30:11 PM",
      "dateFinished": "Jul 7, 2016 1:30:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n###Lazy evaluation by-name versus by-need and memoization \nLazy evaluation can be made futher efficeint through memorization. This introduces the concepts of (1) lazy evaluation by-name where the computation of a variable is delayed until necessary and repeated each time the variable is used; and Lazy evaluation by-need where the computation of a variable is delayed until necessary and cached. To achieve this in Scala, the ``lazy`` keyword/ modifier is used.\n\n```\ndef square (x:Int): Int \u003d{\n    x*x\n}\n\nlazy val y \u003d {println(square(1)); println (square(3+3+3)); \"here!\" + \u0027 \u0027 + square(1).toString+ \u0027 \u0027+ square(3+3+3).toString }\nprintln(\"now\")\nprintln(y)\n```\nOutputs:\n```\nnow \n1 \n81 \nhere! 1 18\n```\n\nNotice by using the ``lazy`` modifer here, the execution of the ``println`` function in y is delayed until **println(y)** is actually called.\nFor computations with large arrays, this can be an especially useful tool to address memory usage and program efficiency. ",
      "dateUpdated": "Jul 14, 2016 3:12:29 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466447208769_1298805995",
      "id": "20160620-112648_1141875874",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eLazy evaluation by-name versus by-need and memoization\u003c/h3\u003e\n\u003cp\u003eLazy evaluation can be made futher efficeint through memorization. This introduces the concepts of (1) lazy evaluation by-name where the computation of a variable is delayed until necessary and repeated each time the variable is used; and Lazy evaluation by-need where the computation of a variable is delayed until necessary and cached. To achieve this in Scala, the \u003ccode\u003elazy\u003c/code\u003e keyword/ modifier is used.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edef square (x:Int): Int \u003d{\n    x*x\n}\n\nlazy val y \u003d {println(square(1)); println (square(3+3+3)); \"here!\" + \u0027 \u0027 + square(1).toString+ \u0027 \u0027+ square(3+3+3).toString }\nprintln(\"now\")\nprintln(y)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOutputs:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003enow \n1 \n81 \nhere! 1 18\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice by using the \u003ccode\u003elazy\u003c/code\u003e modifer here, the execution of the \u003ccode\u003eprintln\u003c/code\u003e function in y is delayed until \u003cstrong\u003eprintln(y)\u003c/strong\u003e is actually called.\n\u003cbr  /\u003eFor computations with large arrays, this can be an especially useful tool to address memory usage and program efficiency.\u003c/p\u003e\n"
      },
      "dateCreated": "Jun 20, 2016 11:26:48 AM",
      "dateStarted": "Jul 10, 2016 7:50:06 PM",
      "dateFinished": "Jul 10, 2016 7:50:10 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n###Lazy evaluation and pipelines in Spark\nDuring manipulation of data, the is customary to create intermediate data objects. This can quickly lead to memory leaks, and reduced runtimes for large datasets as memory access is expensive. The idea behind pipelines is to avoid creating intermediary arrays during the chain execution. Instead, perform all operations on a single element in place. \n\n\n###Pipelines and deferred execution\nAs if one couldn\u0027t get lazier, the Spark and SciSpark environment allow for deferred execution whereby the pipeline/chain of computations is not evaluated until ```.value()``` is called on the RDD or sRDD respectively. ",
      "dateUpdated": "Jul 14, 2016 3:14:03 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466453083703_-1748604581",
      "id": "20160620-130443_1827673449",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eLazy evaluation and pipelines in Spark\u003c/h3\u003e\n\u003cp\u003eDuring manipulation of data, the is customary to create intermediate data objects. This can quickly lead to memory leaks, and reduced runtimes for large datasets as memory access is expensive. The idea behind pipelines is to avoid creating intermediary arrays during the chain execution. Instead, perform all operations on a single element in place.\u003c/p\u003e\n\u003ch3\u003ePipelines and deferred execution\u003c/h3\u003e\n\u003cp\u003eAs if one couldn\u0027t get lazier, the Spark and SciSpark environment allow for deferred execution whereby the pipeline/chain of computations is not evaluated until \u003ccode\u003e`.value()\u003c/code\u003e` is called on the RDD or sRDD respectively.\u003c/p\u003e\n"
      },
      "dateCreated": "Jun 20, 2016 1:04:43 PM",
      "dateStarted": "Jul 14, 2016 3:14:01 AM",
      "dateFinished": "Jul 14, 2016 3:14:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n##Example with real data\nThe data used in this notebook is the [Tropical Rainfall Measuring Mission (TRMM) 0.25° x 0.25°degree 3-hourly dataset](http://disc.sci.gsfc.nasa.gov/precipitation/documentation/TRMM_README/TRMM_3B42_readme.shtml) acquired from the [GES DIS Mirador site] (http://mirador.gsfc.nasa.gov/). \n\nIn this example, we will examine the areas within a given domain impacted by rainfall rates of various rates. We assume the following rates to be associated with weather phenomenon. \n\n\u003ctable width\u003d\"100%\"\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003e\u003cb\u003eType of Storm\u003c/b\u003e\u003c/td\u003e\n\n      \u003ctd\u003e\u003cb\u003eRainfall Rate\u003c/b\u003e\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eLight Rain\u003c/td\u003e\n\n      \u003ctd\u003e2.0 - 4.9 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eModerate\u003c/td\u003e\n\n      \u003ctd\u003e5.0 - 9.9 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eHeavy\u003c/td\u003e\n\n      \u003ctd\u003e10.0 - 40.0 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eViolent\u003c/td\u003e\n\n      \u003ctd\u003e\u003e 40.0 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\nAs an application, let\u0027s consider that for situations such as model evaluations based on changing parameterization schemes, comparing data source outputs and even insurance payouts, it is useful to be able to determine the rainfall rates over consecutive areas.",
      "dateUpdated": "Jul 14, 2016 8:57:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466457106313_211652717",
      "id": "20160620-141146_1124446239",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExample with real data\u003c/h2\u003e\n\u003cp\u003eThe data used in this notebook is the \u003ca href\u003d\"http://disc.sci.gsfc.nasa.gov/precipitation/documentation/TRMM_README/TRMM_3B42_readme.shtml\"\u003eTropical Rainfall Measuring Mission (TRMM) 0.25° x 0.25°degree 3-hourly dataset\u003c/a\u003e acquired from the \u003ca href\u003d\"http://mirador.gsfc.nasa.gov/\"\u003eGES DIS Mirador site\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIn this example, we will examine the areas within a given domain impacted by rainfall rates of various rates. We assume the following rates to be associated with weather phenomenon.\u003c/p\u003e\n\u003ctable width\u003d\"100%\"\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003e\u003cb\u003eType of Storm\u003c/b\u003e\u003c/td\u003e\n\n      \u003ctd\u003e\u003cb\u003eRainfall Rate\u003c/b\u003e\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eLight Rain\u003c/td\u003e\n\n      \u003ctd\u003e2.0 - 4.9 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eModerate\u003c/td\u003e\n\n      \u003ctd\u003e5.0 - 9.9 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eHeavy\u003c/td\u003e\n\n      \u003ctd\u003e10.0 - 40.0 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n\n    \u003ctr\u003e\n      \u003ctd align\u003d\"center\"\u003eViolent\u003c/td\u003e\n\n      \u003ctd\u003e\u003e 40.0 mm/hr\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eAs an application, let\u0027s consider that for situations such as model evaluations based on changing parameterization schemes, comparing data source outputs and even insurance payouts, it is useful to be able to determine the rainfall rates over consecutive areas.\u003c/p\u003e\n"
      },
      "dateCreated": "Jun 20, 2016 2:11:46 PM",
      "dateStarted": "Jul 14, 2016 8:55:04 AM",
      "dateFinished": "Jul 14, 2016 8:55:08 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Imports and create sciSpark context",
      "text": "//generic imports\nimport java.io.{ File, PrintWriter }\nimport scala.collection.mutable\n\n//SciSpark imports\nimport org.dia.Parsers\nimport org.dia.urlgenerators.OpenDapTRMMURLGenerator\nimport org.dia.core.{ SciSparkContext, SciTensor }\nimport org.dia.algorithms.mcc.MCCOps\nimport org.dia.utils.NetCDFUtils\nimport org.dia.tensors.AbstractTensor\n\nval dssc44 \u003d new SciSparkContext(sc)",
      "dateUpdated": "Jul 18, 2016 3:46:29 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "tableHide": true,
        "lineNumbers": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466466369259_461989778",
      "id": "20160620-164609_265714354",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import java.io.{File, PrintWriter}\nimport scala.collection.mutable\nimport org.dia.Parsers\nimport org.dia.urlgenerators.OpenDapTRMMURLGenerator\nimport org.dia.core.{SciSparkContext, SciTensor}\nimport org.dia.algorithms.mcc.MCCOps\nimport org.dia.utils.NetCDFUtils\nimport org.dia.tensors.AbstractTensor\ndssc44: org.dia.core.SciSparkContext \u003d org.dia.core.SciSparkContext@7d1849dd\n"
      },
      "dateCreated": "Jun 20, 2016 4:46:09 PM",
      "dateStarted": "Jul 18, 2016 3:46:30 AM",
      "dateFinished": "Jul 18, 2016 3:46:35 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n####Load data from OPeNDAP\nIn SciSpark, this a two-step process.\n1. The user needs to identify the dates for retrieval. Currently, we can access TRMM data at the [NASA OPeNDAP URL](http://disc2.nascom.nasa.gov/opendap/TRMM_L3/TRMM_3B42_daily/). The paths for each file between the dates are generated and stored into a file on HDFS. \n2. The user identifies this file for loading the netCDF files. This leads to the parellel retrieval of the URLs from the OPeNDAP server. Of course, this can lead to server throttling, hence, the user should exercise caution and consideration using this feature. ",
      "dateUpdated": "Jul 1, 2016 12:50:33 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466466731371_319785927",
      "id": "20160620-165211_1020277328",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4\u003eLoad data from OPeNDAP\u003c/h4\u003e\n\u003cp\u003eIn SciSpark, this a two-step process.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe user needs to identify the dates for retrieval. Currently, we can access TRMM data at the \u003ca href\u003d\"http://disc2.nascom.nasa.gov/opendap/TRMM_L3/TRMM_3B42_daily/\"\u003eNASA OPeNDAP URL\u003c/a\u003e. The paths for each file between the dates are generated and stored into a file on HDFS.\u003c/li\u003e\n\u003cli\u003eThe user identifies this file for loading the netCDF files. This leads to the parellel retrieval of the URLs from the OPeNDAP server. Of course, this can lead to server throttling, hence, the user should exercise caution and consideration using this feature.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Jun 20, 2016 4:52:11 PM",
      "dateStarted": "Jul 1, 2016 8:27:49 AM",
      "dateFinished": "Jul 1, 2016 8:27:49 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "OpenDapTRMMURLGenerator.run(false, \"hdfs://localhost:9000/workshop_s3/201/\",\"TRMM3hrly2010.txt\", \"201006150000\", \"201006150900\", 2, List(\"precipitation,1,1439,1,399\", \"nlon,1,1439\", \"nlat,1,399\"))\n\nval sRDD7 \u003d dssc44.NetcdfFile(\"hdfs://localhost:9000/user/root/TRMM3hrly2010.txt\", List(\"precipitation\", \"nlat\", \"nlon\"), 3)\n\n// parse the date out from the openDap URL\nval labeled7 \u003d sRDD7.map(p1 \u003d\u003e {\n    val filename \u003d p1.metaData(\"SOURCE\").split(\"/\").last.split(\"\\\\.\")\n    val fileDate \u003d (filename(1) + filename(2)).toInt\n    p1.insertDictionary((\"Date\", fileDate.toString))\n    p1\n})",
      "dateUpdated": "Jul 18, 2016 3:46:58 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": false,
        "tableHide": false,
        "lineNumbers": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1467386769691_-1459161744",
      "id": "20160701-082609_199793417",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "org.apache.hadoop.hdfs.client.HdfsDataOutputStream@2188c787\nsRDD7: org.apache.spark.rdd.RDD[org.dia.core.SciTensor] \u003d MapPartitionsRDD[19] at map at SciSparkContext.scala:93\nlabeled7: org.apache.spark.rdd.RDD[org.dia.core.SciTensor] \u003d MapPartitionsRDD[20] at map at \u003cconsole\u003e:49\n"
      },
      "dateCreated": "Jul 1, 2016 8:26:09 AM",
      "dateStarted": "Jul 18, 2016 3:46:59 AM",
      "dateFinished": "Jul 18, 2016 3:47:03 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "println(labeled7.collect().toList)",
      "dateUpdated": "Jul 18, 2016 3:48:04 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1468838856740_390142389",
      "id": "20160718-034736_130696297",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "List(Variable in use \u003d nlon\nSet(nlat, nlon, precipitation)\n(Date,2010061500)\n(SOURCE,http://disc2.nascom.nasa.gov/opendap/hyrax/TRMM_L3/TRMM_3B42/2010/165/3B42.20100615.00.7A.HDF.Z?precipitation[0:1:1439][0:1:399],nlon[0:1:1439],nlat[0:1:399])\n, Variable in use \u003d nlon\nSet(nlat, nlon, precipitation)\n(Date,2010061503)\n(SOURCE,http://disc2.nascom.nasa.gov/opendap/hyrax/TRMM_L3/TRMM_3B42/2010/166/3B42.20100615.03.7A.HDF.Z?precipitation[0:1:1439][0:1:399],nlon[0:1:1439],nlat[0:1:399])\n, Variable in use \u003d nlon\nSet(nlat, nlon, precipitation)\n(Date,2010061506)\n(SOURCE,http://disc2.nascom.nasa.gov/opendap/hyrax/TRMM_L3/TRMM_3B42/2010/166/3B42.20100615.06.7A.HDF.Z?precipitation[0:1:1439][0:1:399],nlon[0:1:1439],nlat[0:1:399])\n, Variable in use \u003d nlon\nSet(nlat, nlon, precipitation)\n(Date,2010061509)\n(SOURCE,http://disc2.nascom.nasa.gov/opendap/hyrax/TRMM_L3/TRMM_3B42/2010/166/3B42.20100615.09.7A.HDF.Z?precipitation[0:1:1439][0:1:399],nlon[0:1:1439],nlat[0:1:399])\n)\n"
      },
      "dateCreated": "Jul 18, 2016 3:47:36 AM",
      "dateStarted": "Jul 18, 2016 3:48:08 AM",
      "dateFinished": "Jul 18, 2016 3:48:30 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Summary:\nLazy evaluation is quite handy for:\n1. stringing multiple calculations/ evaluations to create calculable streams (infinite length lists) without infinite loops - for example gathering data from an instrument in real-time;  \n2. addressing memory concerns during computation;\n3. improving the performance by avoiding needless calculations\n4. controlling the program flow outside of the primitive types\n\nLazy evaluations can reduce runtimes for certain (functions) implementations exponentially, and is both efficient and expressive.\n\nOf course, the key to acheiving the core runtime benefit performance and optimal memory utilization is in the implementation of the problem.",
      "dateUpdated": "Jul 18, 2016 3:52:47 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466455948870_641527273",
      "id": "20160620-135228_1005918920",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eLazy evaluation is quite handy for:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003estringing multiple calculations/ evaluations to create calculable streams (infinite length lists) without infinite loops - for example gathering data from an instrument in real-time;\u003c/li\u003e\n\u003cli\u003eaddressing memory concerns during computation;\u003c/li\u003e\n\u003cli\u003eimproving the performance by avoiding needless calculations\u003c/li\u003e\n\u003cli\u003econtrolling the program flow outside of the primitive types\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLazy evaluations can reduce runtimes for certain (functions) implementations exponentially, and is both efficient and expressive.\u003c/p\u003e\n\u003cp\u003eOf course, the key to acheiving the core runtime benefit performance and optimal memory utilization is in the implementation of the problem.\u003c/p\u003e\n"
      },
      "dateCreated": "Jun 20, 2016 1:52:28 PM",
      "dateStarted": "Jun 20, 2016 2:40:46 PM",
      "dateFinished": "Jun 20, 2016 2:40:46 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1466697976730_323274939",
      "id": "20160623-090616_1638699114",
      "dateCreated": "Jun 23, 2016 9:06:16 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "201-2 More SciSpark API \u0026 LazyEvaluation",
  "id": "2BQ4RQABT",
  "angularObjects": {
    "2BATG925A": [],
    "2BCTKA5P2": [],
    "2B9VMB5BB": [],
    "2BAA8ZT1F": [],
    "2BCYFRWUC": [],
    "2BCC68R3T": [],
    "2BA8C2CJ4": [],
    "2B9AHSVAD": [],
    "2BCZV9QGQ": [],
    "2B9U51XQ6": [],
    "2B9VX5KPM": [],
    "2BAM6HXAB": [],
    "2B9AFX9BM": [],
    "2BQMW3S3P": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}
