{
  "paragraphs": [
    {
      "title": "Load \u0026 Split a text file",
      "text": "// Create a Scala Spark Context.\r//val conf \u003d new SparkConf().setAppName(\"wordCount\") val sc \u003d new SparkContext(conf)\r// Load our input data.\rval input \u003d sc.textFile(\"/usr/share/dict/words\")",
      "dateUpdated": "May 11, 2016 1:43:26 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "tableHide": false,
        "editorHide": false,
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529129418_-1948449115",
      "id": "20160320-195849_1476986233",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "input: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[1062] at textFile at \u003cconsole\u003e:181\n"
      },
      "dateCreated": "Mar 20, 2016 7:58:49 PM",
      "dateStarted": "May 11, 2016 1:43:26 PM",
      "dateFinished": "May 11, 2016 1:43:27 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Split Lines into Words",
      "text": "val words \u003d input.flatMap(line \u003d\u003e line.split(\" \"))",
      "dateUpdated": "May 10, 2016 6:55:32 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "tableHide": false,
        "editorHide": false,
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529195894_1343770602",
      "id": "20160320-195955_1511332517",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "words: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[555] at flatMap at \u003cconsole\u003e:125\n"
      },
      "dateCreated": "Mar 20, 2016 7:59:55 PM",
      "dateStarted": "May 10, 2016 6:55:32 PM",
      "dateFinished": "May 10, 2016 6:55:32 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Map words to Tuple of (word, 1)",
      "text": "val counts1 \u003d words.map(word \u003d\u003e (word, 1))",
      "dateUpdated": "May 10, 2016 6:55:34 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529620427_-342566335",
      "id": "20160320-200700_1517255063",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "counts1: org.apache.spark.rdd.RDD[(String, Int)] \u003d MapPartitionsRDD[556] at map at \u003cconsole\u003e:127\n"
      },
      "dateCreated": "Mar 20, 2016 8:07:00 PM",
      "dateStarted": "May 10, 2016 6:55:34 PM",
      "dateFinished": "May 10, 2016 6:55:35 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Reduce by Summation",
      "text": "val counts \u003d counts1.reduceByKey{_ + _}",
      "dateUpdated": "May 10, 2016 6:55:37 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "tableHide": false,
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529246733_-781320166",
      "id": "20160320-200046_1405503179",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "counts: org.apache.spark.rdd.RDD[(String, Int)] \u003d ShuffledRDD[557] at reduceByKey at \u003cconsole\u003e:129\n"
      },
      "dateCreated": "Mar 20, 2016 8:00:46 PM",
      "dateStarted": "May 10, 2016 6:55:37 PM",
      "dateFinished": "May 10, 2016 6:55:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Save Word Counts to File",
      "text": "// Save the word count back out to a text file, causing evaluation.\rcounts.saveAsTextFile(\"/tmp/wordCounts99\")",
      "dateUpdated": "May 10, 2016 6:55:39 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529262485_2055848871",
      "id": "20160320-200102_678899659",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Mar 20, 2016 8:01:02 PM",
      "dateStarted": "May 10, 2016 6:55:39 PM",
      "dateFinished": "May 10, 2016 6:55:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Word Count Program",
      "text": "// Create a Scala Spark Context.\r//val conf \u003d new SparkConf().setAppName(\"wordCount\")\r//val sc \u003d new SparkContext(conf)\r\r// Load our input data.\rval input \u003d sc.textFile(\"/usr/share/dict/words\");\r\r// Split it up into words.\rval words \u003d input.flatMap(line \u003d\u003e line.split(\" \"));\r\r// Transform into pairs and count.\rval counts \u003d words.map(word \u003d\u003e (word, 1)).reduceByKey{_ + _};\r\r// Examine top word.\rcounts.first();\r\r// Save the word count back out to a text file, causing evaluation.\rcounts.saveAsTextFile(\"/tmp/wordCounts98\");\r",
      "dateUpdated": "Mar 23, 2016 3:04:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "tableHide": false,
        "editorHide": false,
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529420692_-615846967",
      "id": "20160320-200340_297959576",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "input: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[118] at textFile at \u003cconsole\u003e:42\nwords: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[119] at flatMap at \u003cconsole\u003e:45\ncounts: org.apache.spark.rdd.RDD[(String, Int)] \u003d ShuffledRDD[121] at reduceByKey at \u003cconsole\u003e:48\n"
      },
      "dateCreated": "Mar 20, 2016 8:03:40 PM",
      "dateStarted": "Mar 23, 2016 3:04:13 PM",
      "dateFinished": "Mar 23, 2016 3:04:24 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Word Count in Python",
      "text": "%pyspark\n#    sc \u003d SparkContext(appName\u003d\"PythonWordCount\")\nlines \u003d sc.textFile(\"/usr/share/dict/words\", 1)\ncounts \u003d lines.flatMap(lambda x: x.split(\u0027 \u0027)) \\\n              .map(lambda x: (x, 1)) \\\n              .reduceByKey(lambda x,y: x + y)\n\noutput \u003d counts.collect()\nfor (word, count) in output:\n    print(\"%s: %i\" % (word, count))",
      "dateUpdated": "Mar 22, 2016 5:08:45 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458538020397_-1127472778",
      "id": "20160320-222700_316630753",
      "dateCreated": "Mar 20, 2016 10:27:00 PM",
      "dateStarted": "Mar 22, 2016 3:49:15 PM",
      "dateFinished": "Mar 22, 2016 3:49:16 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Compute PI using Monte Carlo",
      "text": "// Compute PI using Monte Carlo.\nval slices \u003d 1000\nval n \u003d math.min(100000L * slices, Int.MaxValue).toInt // avoid overflow\nval count \u003d sc.parallelize(1 until n, slices).map { i \u003d\u003e\n      val x \u003d Math.random() * 2 - 1 \n      val y \u003d Math.random() * 2 - 1\n      if (x*x + y*y \u003c 1) 1 else 0\n}.reduce(_ + _)\nprintln(\"\\nPi is roughly \" + 4.0 * count / n)",
      "dateUpdated": "May 10, 2016 6:56:33 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529543477_1364271731",
      "id": "20160320-200543_1718495347",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "slices: Int \u003d 1000\nn: Int \u003d 100000000\ncount: Int \u003d 78544848\n\nPi is roughly 3.14179392\n"
      },
      "dateCreated": "Mar 20, 2016 8:05:43 PM",
      "dateStarted": "May 10, 2016 6:56:33 PM",
      "dateFinished": "May 10, 2016 6:56:55 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Mar 20, 2016 8:22:16 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "tableHide": false,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458529550022_-830351319",
      "id": "20160320-200550_425310862",
      "dateCreated": "Mar 20, 2016 8:05:50 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Brian\u0027s examples",
  "id": "2BATEJKHX",
  "angularObjects": {
    "2BATG925A": [],
    "2BCTKA5P2": [],
    "2B9VMB5BB": [],
    "2BAA8ZT1F": [],
    "2BCYFRWUC": [],
    "2BCC68R3T": [],
    "2BA8C2CJ4": [],
    "2B9AHSVAD": [],
    "2BCZV9QGQ": [],
    "2B9U51XQ6": [],
    "2B9VX5KPM": [],
    "2BAM6HXAB": [],
    "2B9AFX9BM": [],
    "2BBAYHPQT": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}